{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15a3893ef8734795a93b8f6781df9965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e45c9794bef546768767baa5e2d94443",
              "IPY_MODEL_0cefd2ac75224cf49b07a94efb1f8163",
              "IPY_MODEL_8bd2ce68b3c64822af07d53586bf2d93"
            ],
            "layout": "IPY_MODEL_e63a1d6d1879498fa7986c00702be1d3"
          }
        },
        "e45c9794bef546768767baa5e2d94443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3aa28aaecc46098989d755e4241403",
            "placeholder": "​",
            "style": "IPY_MODEL_53dfc2b3a7324fd292cdd1cc7ad7abda",
            "value": "OrphanSimBERT.bin: 100%"
          }
        },
        "0cefd2ac75224cf49b07a94efb1f8163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a765576e9f5047caa3c095d9c6cd19e2",
            "max": 438059110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17e0c98c475a4ea8a6b1d17559e4b468",
            "value": 438059110
          }
        },
        "8bd2ce68b3c64822af07d53586bf2d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a73885839434ac6872eb435a66a5d2f",
            "placeholder": "​",
            "style": "IPY_MODEL_07e0592536544ea1afed15c732fcb5a6",
            "value": " 438M/438M [00:09&lt;00:00, 46.0MB/s]"
          }
        },
        "e63a1d6d1879498fa7986c00702be1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3aa28aaecc46098989d755e4241403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dfc2b3a7324fd292cdd1cc7ad7abda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a765576e9f5047caa3c095d9c6cd19e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e0c98c475a4ea8a6b1d17559e4b468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a73885839434ac6872eb435a66a5d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e0592536544ea1afed15c732fcb5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c9d4c65c0c14baa890dad6201919f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cc936c472e44a62b0ec93ffa634bab8",
              "IPY_MODEL_b603e04ffb824a22a958ffd051da291d",
              "IPY_MODEL_5dd6736f9d5c4f81a05b1babd989ab57"
            ],
            "layout": "IPY_MODEL_280ecdf2bae6468798d29540880f1053"
          }
        },
        "6cc936c472e44a62b0ec93ffa634bab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6073ae107a4c498d20fa1aaef7593b",
            "placeholder": "​",
            "style": "IPY_MODEL_4df3b3b0580641da804a67c929f19733",
            "value": "OrphanSimBERT.bin: 100%"
          }
        },
        "b603e04ffb824a22a958ffd051da291d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6e94c60a314a44ac749e321440afae",
            "max": 438059110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_898ef0a6e6a64d75a41b3e2bc0ebd8cd",
            "value": 438059110
          }
        },
        "5dd6736f9d5c4f81a05b1babd989ab57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3682405dca49b68cff80b51acdf0aa",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe3a6e4eb8b46799571bfc16331703d",
            "value": " 438M/438M [00:09&lt;00:00, 46.6MB/s]"
          }
        },
        "280ecdf2bae6468798d29540880f1053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6073ae107a4c498d20fa1aaef7593b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df3b3b0580641da804a67c929f19733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6e94c60a314a44ac749e321440afae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898ef0a6e6a64d75a41b3e2bc0ebd8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e3682405dca49b68cff80b51acdf0aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe3a6e4eb8b46799571bfc16331703d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LWv3FV-RXVk"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token = \"hf_key\")"
      ],
      "metadata": {
        "id": "vYKfEt_6i0iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "Bi0TqDK_SLxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# makeing repo\n",
        "!huggingface-cli repo create OrphanSimBERT"
      ],
      "metadata": {
        "id": "ma8o_ZcWSNoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting repo\n",
        "#!pip install huggingface_hub\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.delete_repo(repo_id='jabv/OrphanSimBERT')"
      ],
      "metadata": {
        "id": "YqIhQEwkn5gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example finetuuning"
      ],
      "metadata": {
        "id": "iRMyVr9Ojpas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers\n",
        "#from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BertTokenizer, RobertaTokenizer, RobertaModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
        "class BertForSTS(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForSTS, self).__init__()\n",
        "        #self.bert = models.Transformer(\"bert-base-uncased\", max_seq_length=512)\n",
        "        self.bert = models.Transformer('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext', max_seq_length=1000)\n",
        "        #model = AutoModel.from_pretrained(model_name)\n",
        "        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n",
        "        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n",
        "    def forward(self, input_data):\n",
        "        output = self.sts_bert(input_data)['sentence_embedding']\n",
        "        return output\n",
        "# Instantiate the model and move it to GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = BertForSTS()\n",
        "model.to(device)\n",
        "model.eval()\n",
        "def predict_similarity(sentence_pair):\n",
        "  test_input = tokenizer(sentence_pair, padding=True, truncation=True, return_tensors=\"pt\").to(device) # max_length = 512,\n",
        "  test_input['input_ids'] = test_input['input_ids']\n",
        "  test_input['attention_mask'] = test_input['attention_mask']\n",
        "  del test_input['token_type_ids']\n",
        "  output = model(test_input)\n",
        "  sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n",
        "  return sim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/My Drive/Finetunned_Bert_2.pt'\n",
        "model = BertForSTS()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"##########################################################################################\")\n",
        "example_1=[ 'A cat is walking around a house.', 'A woman is peeling potato']\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")\n",
        "\n",
        "print(\"##########################################################################################\")\n",
        "example_1=[  'arterial thoracic outlet syndrome',\n",
        " '''\n",
        " The objective of this project is to study the contribution of hemorrheology to arterial and venous thrombosis using the arterio-venous (A-V)\n",
        "   ''']\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")\n",
        "\n",
        "\n",
        "print(\"##########################################################################################\")\n",
        "example_1=['antisynthetase syndrome',\n",
        " '''\n",
        "  A rare idiopathic inflammatory myopathy (IIM) historically characterized by symmetric proximal muscle weakness, elevated muscle enzymes (creatine kinase), myopathic findings on electromyography, and muscle biopsy showing endomyial infiltration composed mainly of macrophages and lymphocytes. The features are non-specific, thus the disease should be distinguished from similar entities with specific clinical, immunological, histological features, notably dermatomyositis, immune-mediated necrotizing myopathy, anti-synthetase syndrome, inclusion body myositis, and myositis associated with other connective tissue disorder.\n",
        "''']\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")\n",
        "\n",
        "print(\"##########################################################################################\")\n",
        "##(one of its synonym is childhood cancer)\n",
        "example_1=['mismatch repair cancer syndrome 1 '\n",
        ",\n",
        "'''\n",
        "childhood cancer''']\n",
        "\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")\n",
        "\n",
        "print(\"##########################################################################################\")\n",
        "example_1=[  'polymyositis',\n",
        " '''\n",
        " A rare idiopathic inflammatory myopathy (IIM) historically characterized by symmetric proximal muscle weakness, elevated muscle enzymes (creatine kinase), myopathic findings on electromyography, and muscle biopsy showing endomyial infiltration composed mainly of macrophages and lymphocytes. The features are non-specific, thus the disease should be distinguished from similar entities with specific clinical, immunological, histological features, notably dermatomyositis, immune-mediated necrotizing myopathy, anti-synthetase syndrome, inclusion body myositis, and myositis associated with other connective tissue disorder.\n",
        "   '''\n",
        "]\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")\n",
        "\n",
        "def is_about_term(input_text, target_term):\n",
        "  sentence_pair=[input_text, target_term]\n",
        "  test_input = tokenizer(sentence_pair, padding=True, truncation=True, return_tensors=\"pt\").to(device) # max_length = 512,\n",
        "  test_input['input_ids'] = test_input['input_ids']\n",
        "  test_input['attention_mask'] = test_input['attention_mask']\n",
        "  del test_input['token_type_ids']\n",
        "  output = model(test_input)\n",
        "  sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n",
        "  return  round(sim,2)"
      ],
      "metadata": {
        "id": "wKKujkjpSqQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pusing model and tokenizer to repo"
      ],
      "metadata": {
        "id": "_6ih5v4Bj1UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForSTS(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForSTS, self).__init__()\n",
        "        #self.bert = models.Transformer(\"bert-base-uncased\", max_seq_length=512)\n",
        "        self.bert = models.Transformer('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext', max_seq_length=1000)\n",
        "        #model = AutoModel.from_pretrained(model_name)\n",
        "        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n",
        "        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n",
        "    def forward(self, input_data):\n",
        "        output = self.sts_bert(input_data)['sentence_embedding']\n",
        "        return output\n",
        "# Instantiate the model and move it to GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "#drive.mount('/content/drive')\n",
        "PATH = '/content/drive/My Drive/Finetunned_Bert_2.pt'\n",
        "model = BertForSTS()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S_8x006Uydz",
        "outputId": "dcc14564-68bb-442c-ea69-e8a7da8e8f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create OrphanSimBERT_1"
      ],
      "metadata": {
        "id": "jb9clf9KtHmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from huggingface_hub import HfApi, HfFolder, create_repo, upload_file\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Set your Hugging Face token\n",
        "HF_TOKEN = \"hf_key\"\n",
        "\n",
        "# Save the model\n",
        "model_dir = \"OrphanSimBERT_1\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "model_path = os.path.join(model_dir, \"OrphanSimBERT.bin\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# Save the model config\n",
        "config = {\n",
        "    \"architectures\": [\"BertForSTS\"],\n",
        "    \"model_type\": \"bert\",\n",
        "    \"tokenizer_class\": \"BertTokenizer\",\n",
        "    \"pretrained_model_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "}\n",
        "config_path = os.path.join(model_dir, \"config.json\")\n",
        "with open(config_path, 'w') as f:\n",
        "    import json\n",
        "    json.dump(config, f)\n",
        "\n",
        "# Create the repository on Hugging Face\n",
        "repo_name = \"OrphanSimBERT_1\"\n",
        "username = HfApi().whoami(token=HF_TOKEN)[\"name\"]  # Your username on Hugging Face\n",
        "repo_id = f\"{username}/{repo_name}\"\n",
        "\n",
        "api = HfApi()\n",
        "create_repo(repo_id, token=HF_TOKEN, exist_ok=True)\n",
        "\n",
        "# Upload files to the repository\n",
        "upload_file(\n",
        "    path_or_fileobj=model_path,\n",
        "    path_in_repo=\"pytorch_model.bin\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj=config_path,\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj=os.path.join(model_dir, \"tokenizer_config.json\"),\n",
        "    path_in_repo=\"tokenizer_config.json\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj=os.path.join(model_dir, \"vocab.txt\"),\n",
        "    path_in_repo=\"vocab.txt\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "print(\"Model and tokenizer files have been uploaded to the repository.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "15a3893ef8734795a93b8f6781df9965",
            "e45c9794bef546768767baa5e2d94443",
            "0cefd2ac75224cf49b07a94efb1f8163",
            "8bd2ce68b3c64822af07d53586bf2d93",
            "e63a1d6d1879498fa7986c00702be1d3",
            "7a3aa28aaecc46098989d755e4241403",
            "53dfc2b3a7324fd292cdd1cc7ad7abda",
            "a765576e9f5047caa3c095d9c6cd19e2",
            "17e0c98c475a4ea8a6b1d17559e4b468",
            "4a73885839434ac6872eb435a66a5d2f",
            "07e0592536544ea1afed15c732fcb5a6"
          ]
        },
        "id": "Lc_WrZqFxsOP",
        "outputId": "25728535-08ce-465e-ad37-2758f851ca26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OrphanSimBERT.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15a3893ef8734795a93b8f6781df9965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer files have been uploaded to the repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.delete_repo(repo_id='jabv/OrphanSimBERT_1')"
      ],
      "metadata": {
        "id": "xH0xfSA623rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from huggingface_hub import HfApi, HfFolder, create_repo, upload_file\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class BertForSTS(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForSTS, self).__init__()\n",
        "        self.bert = models.Transformer('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext', max_seq_length=1000)\n",
        "        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n",
        "        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        output = self.sts_bert(input_data)['sentence_embedding']\n",
        "        return output\n",
        "\n",
        "# Instantiate the model and move it to GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "PATH = '/content/drive/My Drive/Finetunned_Bert_2.pt'\n",
        "model = BertForSTS()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# Set your Hugging Face token\n",
        "HF_TOKEN = os.getenv('hf_key')  # Ensure you set this environment variable securely\n",
        "\n",
        "# Save the model\n",
        "model_dir = \"OrphanSimBERT_1\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "model_path = os.path.join(model_dir, \"OrphanSimBERT.bin\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# Save the model config\n",
        "config = {\n",
        "    \"architectures\": [\"BertForSTS\"],\n",
        "    \"model_type\": \"bert\",\n",
        "    \"tokenizer_class\": \"BertTokenizer\",\n",
        "    \"pretrained_model_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "}\n",
        "config_path = os.path.join(model_dir, \"config.json\")\n",
        "with open(config_path, 'w') as f:\n",
        "    import json\n",
        "    json.dump(config, f)\n",
        "\n",
        "# Create the repository on Hugging Face\n",
        "api = HfApi()\n",
        "username = api.whoami(token=HF_TOKEN)[\"name\"]\n",
        "repo_name = \"OrphanSimBERT_1\"\n",
        "repo_id = f\"{username}/{repo_name}\"\n",
        "\n",
        "api.create_repo(repo_id, token=HF_TOKEN, exist_ok=True)\n",
        "\n",
        "# Upload files to the repository\n",
        "upload_file(\n",
        "    path_or_fileobj=model_path,\n",
        "    path_in_repo=\"pytorch_model.bin\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj=config_path,\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN\n",
        ")\n",
        "\n",
        "# Upload tokenizer files\n",
        "for file_name in [\"tokenizer_config.json\", \"vocab.txt\"]:\n",
        "    file_path = os.path.join(model_dir, file_name)\n",
        "    if os.path.exists(file_path):\n",
        "        upload_file(\n",
        "            path_or_fileobj=file_path,\n",
        "            path_in_repo=file_name,\n",
        "            repo_id=repo_id,\n",
        "            token=HF_TOKEN\n",
        "        )\n",
        "\n",
        "print(\"Model and tokenizer files have been uploaded to the repository.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "3c9d4c65c0c14baa890dad6201919f6d",
            "6cc936c472e44a62b0ec93ffa634bab8",
            "b603e04ffb824a22a958ffd051da291d",
            "5dd6736f9d5c4f81a05b1babd989ab57",
            "280ecdf2bae6468798d29540880f1053",
            "8c6073ae107a4c498d20fa1aaef7593b",
            "4df3b3b0580641da804a67c929f19733",
            "8e6e94c60a314a44ac749e321440afae",
            "898ef0a6e6a64d75a41b3e2bc0ebd8cd",
            "6e3682405dca49b68cff80b51acdf0aa",
            "2fe3a6e4eb8b46799571bfc16331703d"
          ]
        },
        "id": "AcGHkC_h20nQ",
        "outputId": "3888a221-611d-4e5b-d4e6-96a824f4a3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OrphanSimBERT.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c9d4c65c0c14baa890dad6201919f6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer files have been uploaded to the repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### pushing model\n",
        "from transformers import BertConfig, BertModel\n",
        "config = BertConfig()\n",
        "model = BertModel(config)\n",
        "model.push_to_hub(\"jabv/OrphanSimBERT\")\n",
        "# reload\n",
        "model = BertModel.from_pretrained(\"jabv/OrphanSimBERT\")"
      ],
      "metadata": {
        "id": "3dwxLhutWmEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### pushing tokenizer\n",
        "from transformers import BertTokenizer\n",
        "# Instantiate your tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext')\n",
        "tokenizer_directory = \"./tokenizer_directory\"\n",
        "# Save the tokenizer files to the directory\n",
        "tokenizer.save_pretrained(tokenizer_directory)\n",
        "tokenizer.push_to_hub(\"jabv/OrphanSimBERT_1\")"
      ],
      "metadata": {
        "id": "fnt_5GUub3uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "22QJuToRkkAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EGAyyZgoT4k",
        "outputId": "2e5c874d-3a87-40ef-db26-5602b7c7225d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, models\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"jabv/OrphanSimBERT_1\")\n",
        "\n",
        "class OrphanSimBERT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OrphanSimBERT, self).__init__()\n",
        "        self.bert = models.Transformer('jabv/OrphanSimBERT_1')\n",
        "        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n",
        "        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        output = self.sts_bert(input_data)['sentence_embedding']\n",
        "        return output\n",
        "\n",
        "def predict_similarity(sentence_pair):\n",
        "    test_input = tokenizer(sentence_pair, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    test_input['input_ids'] = test_input['input_ids']\n",
        "    test_input['attention_mask'] = test_input['attention_mask']\n",
        "    del test_input['token_type_ids']\n",
        "    output = model(test_input)\n",
        "    sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n",
        "    return sim\n",
        "\n",
        "model = OrphanSimBERT()\n",
        "\n",
        "example_1 = [  'arterial thoracic outlet syndrome',\n",
        " '''The objective of this project is to study the contribution of hemorrheology to arterial and venous thrombosis using the arterio-venous (A-V)\n",
        "   ''']\n",
        "example_2=[ 'A cat is walking around a house.', 'A woman is peeling potato']\n",
        "\n",
        "print(f\"Predicted similarity score for example_1: {round(predict_similarity(example_1), 2)}\")\n",
        "print(f\"Predicted similarity score for example_2: {round(predict_similarity(example_2), 2)}\")"
      ],
      "metadata": {
        "id": "Us9pAuZpVqTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_1 = [  'arterial thoracic outlet syndrome',\n",
        " '''The objective of this project is to study the contribution of hemorrheology to arterial and venous thrombosis using the arterio-venous (A-V)\n",
        "   ''']\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")"
      ],
      "metadata": {
        "id": "PSA06aj3rOp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_similarity(sentence_pair):\n",
        "    test_input = tokenizer(sentence_pair, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    test_input['input_ids'] = test_input['input_ids']\n",
        "    test_input['attention_mask'] = test_input['attention_mask']\n",
        "    del test_input['token_type_ids']\n",
        "    output = model(test_input)\n",
        "    sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n",
        "    return sim\n",
        "example_1=[ 'A cat is walking around a house.', 'A woman is peeling potato']\n",
        "model = OrphanSimBERT()\n",
        "\n",
        "\n",
        "print(f\"Sentence 1: {example_1[0]}\")\n",
        "print(f\"Sentence 2: {example_1[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")"
      ],
      "metadata": {
        "id": "jVf2vkDNrLSN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}